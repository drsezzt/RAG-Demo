# è°ƒç”¨llm_serviceè·å–å…³é”®è¯
# è°ƒç”¨retriverè·å–æ–‡æ¡£
# è°ƒç”¨llm_clientç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ

import logging
import numpy as np
from typing import List, Tuple, Optional
from rag_app.core import prompts
from rag_app.core import robust_json_parser
from shared.config import get_rag_config
from rag_app.core.interface import ILLMClient, IVectorStoreService


logger = logging.getLogger("RAG_APP")

REPLY_REPORT_TEMPLATE = """
### âš–ï¸ æ³•å¾‹å›å¤æŠ¥å‘Š

**ã€æ ¸å¿ƒæ³•æ¡ã€‘**ï¼š{doc_title}

**ã€æ³•æ¡åŸæ–‡ã€‘**ï¼š
> {doc_content}

---

**ã€å¾‹å¸ˆåˆ†æã€‘**ï¼š
* **åœºæ™¯åˆ¤æ–­**ï¼š{intent_analysis}
* **æ³•å¾‹ç»“è®º**ï¼š**{conclusion}**
* **é€»è¾‘æ¨å¯¼**ï¼š{detailed_logic}

**ã€ğŸ’¡ é¿å‘æç¤ºã€‘**ï¼š
{risk_tips}

---
*å…è´£å£°æ˜ï¼šæœ¬å›å¤ç”± AI å¾‹å¸ˆåŠ©æ‰‹æ ¹æ®å…¬å¼€æ³•æ¡ç”Ÿæˆï¼Œä¸æ„æˆæ­£å¼æ³•å¾‹æ„è§ã€‚*
"""

def cosine_sim(a: np.ndarray, b: np.ndarray) -> float:
    """è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦"""
    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))

class RAGService:
    """RAG æœåŠ¡ï¼Œè´Ÿè´£å®Œæ•´çš„ RAG æµç¨‹"""

    def __init__(
        self,
        llm_client: ILLMClient,
        vector_db: IVectorStoreService
    ):
        """
        åˆå§‹åŒ– RAG æœåŠ¡

        Args:
            llm_client: LLM å®¢æˆ·ç«¯æ¥å£
            vector_db: å‘é‡å­˜å‚¨æœåŠ¡æ¥å£
        """
        self.llm = llm_client
        self.vdb = vector_db

        # åŠ è½½å…¨å±€é…ç½®
        self.rag_config = get_rag_config()

        logger.info(
            "RAGService initialized with config: "
            f"similarity_threshold={self.rag_config.similarity_threshold}, "
            f"top_k={self.rag_config.top_k_retrieval}, "
            f"max_articles={self.rag_config.max_retrieved_articles}"
        )

    def rewrite_query(self, user_input: str) -> dict:
        """
        é‡å†™æŸ¥è¯¢ï¼šæ„å›¾è¯†åˆ«ä¸å…³é”®è¯æå–

        Args:
            user_input: ç”¨æˆ·è¾“å…¥

        Returns:
            dict: åŒ…å«æ„å›¾å’Œå…³é”®è¯çš„å­—å…¸
        """
        logger.info("op=rewrite_query_start")

        # ä½¿ç”¨é…ç½®ä¸­çš„ LLM å‚æ•°
        prompt = prompts.QUERY_REWRITE_TEMPLATE.format(user_input=user_input)
        response = self.llm.chat(
            prompt,
            temperature=self.rag_config.chat_temperature,
            top_p=self.rag_config.chat_top_p,
            max_tokens=self.rag_config.chat_max_tokens
        )
        intent = robust_json_parser(response)

        logger.info("op=rewrite_query_done")

        return intent

    def retrieve(self, query: str) -> List[Tuple[float, dict]]:
        """
        æ£€ç´¢ç›¸å…³æ–‡æ¡£

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬

        Returns:
            List[Tuple[float, dict]]: æ£€ç´¢ç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸º(ç›¸ä¼¼åº¦åˆ†æ•°, æ–‡ç« å…ƒæ•°æ®)
        """
        logger.info("op=retrieve_start")

        if self.vdb is None:
            return []

        # ä½¿ç”¨é…ç½®ä¸­çš„æ£€ç´¢å‚æ•°
        results = self.vdb.search(query, self.rag_config.top_k_retrieval)

        article_ids = set()

        for r in results:
            # æ³¨æ„ï¼šè¿™é‡Œä»ç„¶å­˜åœ¨è€¦åˆï¼Œéœ€è¦åç»­é‡æ„
            # ç†æƒ³æƒ…å†µä¸‹åº”è¯¥é€šè¿‡æ¥å£æ–¹æ³•è·å–ï¼Œè€Œä¸æ˜¯ç›´æ¥è®¿é—®å†…éƒ¨å±æ€§
            store = self.vdb.store  # ä¸´æ—¶è§£å†³æ–¹æ¡ˆ
            chunk = store.get(int(r["chunk_id"]))
            article_ids.update(chunk.article_ids)

        # è·å–åµŒå…¥å™¨
        embedder = self.vdb.embedder  # ä¸´æ—¶è§£å†³æ–¹æ¡ˆ
        q_vec = embedder.embed_query(query)

        articles = []

        for aid in article_ids:
            # è·å–æ–‡ç« å‘é‡
            article_store = self.vdb.article_store  # ä¸´æ—¶è§£å†³æ–¹æ¡ˆ
            vec = article_store.get(aid)
            if vec is not None:
                score = cosine_sim(q_vec, vec)

                # è·å–æ–‡ç« å…ƒæ•°æ®
                metadata = self.vdb.metadata  # ä¸´æ—¶è§£å†³æ–¹æ¡ˆ
                article_meta = metadata.get_article(aid)
                if article_meta:
                    articles.append((score, article_meta))

        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        articles.sort(key=lambda x: x[0], reverse=True)

        # ä½¿ç”¨é…ç½®ä¸­çš„æœ€å¤§æ–‡ç« æ•°
        max_articles = self.rag_config.max_retrieved_articles
        result = articles[:max_articles]

        logger.info("op=retrieve_done count=%d", len(result))

        return result

    def generate_answer(
        self,
        user_input: str,
        articles: List[Tuple[float, dict]]
    ) -> str:
        """
        ç”Ÿæˆç­”æ¡ˆ

        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            articles: æ£€ç´¢åˆ°çš„æ–‡ç« åˆ—è¡¨

        Returns:
            str: ç”Ÿæˆçš„ç­”æ¡ˆ
        """
        logger.info(
            "op=generate_answer_start "
            f"user_input={user_input} "
            f"article_count={len(articles)}"
        )

        if not articles:
            return "æœªæ£€ç´¢åˆ°ç›¸å…³çŸ¥è¯†æ–‡æ¡£ã€‚"

        # è·å–æœ€ç›¸å…³æ–‡æ¡£çš„åˆ†æ•°
        best_score = articles[0][0]

        # ä½¿ç”¨é…ç½®ä¸­çš„ç›¸ä¼¼åº¦é˜ˆå€¼
        if best_score < self.rag_config.similarity_threshold:
            return "æŠ±æ­‰ï¼Œæ£€ç´¢åˆ°çš„çŸ¥è¯†æ–‡æ¡£ç›¸å…³æ€§è¾ƒä½ï¼Œå»ºè®®å’¨è¯¢äººå·¥ã€‚"

        # åŸºäºä¸Šä¸‹æ–‡ç”Ÿæˆç­”æ¡ˆ
        content = "\n".join([art[1].text for art in articles])
        prompt = prompts.RAG_GENERATE_TEMPLATE.format(content=content, user_input=user_input)

        llm_raw_output = self.llm.chat(
            prompt,
            temperature=self.rag_config.chat_temperature,
            top_p=self.rag_config.chat_top_p,
            max_tokens=self.rag_config.chat_max_tokens,
        )

        # è§£æ LLM è¾“å‡ºçš„ JSON
        analysis = robust_json_parser(llm_raw_output)
        if analysis:
            title = " ".join([art[1].title for art in articles])
            tips_str = "\n".join([f"- {tip}" for tip in analysis.get("risk_tips", [])])

            final_report = REPLY_REPORT_TEMPLATE.format(
                doc_title=title,
                doc_content=content,
                intent_analysis=analysis.get("intent_analysis", "æœªçŸ¥åœºæ™¯"),
                conclusion=analysis.get("conclusion", "è¯·å’¨è¯¢äººå·¥ç¡®è®¤"),
                detailed_logic=analysis.get("detailed_logic", "åˆ†æè¿‡ç¨‹ç¼ºå¤±"),
                risk_tips=tips_str
            )
        else:
            final_report = llm_raw_output

        logger.info("op=generate_answer_done")

        return final_report

    def call_rag_flow(self, user_input: str) -> str:
        """
        æ‰§è¡Œå®Œæ•´çš„ RAG æµç¨‹

        Args:
            user_input: ç”¨æˆ·è¾“å…¥

        Returns:
            str: RAG ç”Ÿæˆçš„ç­”æ¡ˆ
        """
        logger.info(
            "op=call_rag_flow_start "
            f"user_input={user_input}"
        )

        # 1. æŸ¥è¯¢é‡å†™
        try:
            intent = self.rewrite_query(user_input)
            search_words = intent.get('search_words', user_input)
        except Exception as e:
            logger.exception(
                "op=call_rag_flow_exception "
                f"exception={type(e).__name__}"
            )
            search_words = user_input

        # 2. æ–‡æ¡£æ£€ç´¢
        articles = self.retrieve(search_words)

        # 3. ç­”æ¡ˆç”Ÿæˆ
        answer = self.generate_answer(user_input, articles)

        logger.info(
            "op=call_rag_flow_done "
            f"answer_length={len(answer)}"
        )

        return answer