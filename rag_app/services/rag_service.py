# è°ƒç”¨llm_serviceè·å–å…³é”®è¯
# è°ƒç”¨retriverè·å–æ–‡æ¡£
# è°ƒç”¨llm_clientç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ

import json
import logging
from rag_app.core import prompts
from rag_app.core import legal_search
from rag_app.core import robust_json_parser

logger = logging.getLogger("RAG_APP")

REPLY_REPORT_TEMPLATE = """
### âš–ï¸ æ³•å¾‹å›å¤æŠ¥å‘Š

**ã€æ ¸å¿ƒæ³•æ¡ã€‘**ï¼š{law_title}

**ã€æ³•æ¡åŸæ–‡ã€‘**ï¼š
> {law_content}

---

**ã€å¾‹å¸ˆåˆ†æã€‘**ï¼š
* **åœºæ™¯åˆ¤æ–­**ï¼š{intent_analysis}
* **æ³•å¾‹ç»“è®º**ï¼š**{conclusion}**
* **é€»è¾‘æ¨å¯¼**ï¼š{detailed_logic}

**ã€ğŸ’¡ é¿å‘æç¤ºã€‘**ï¼š
{risk_tips}

---
*å…è´£å£°æ˜ï¼šæœ¬å›å¤ç”± AI å¾‹å¸ˆåŠ©æ‰‹æ ¹æ®å…¬å¼€æ³•æ¡ç”Ÿæˆï¼Œä¸æ„æˆæ­£å¼æ³•å¾‹æ„è§ã€‚*
"""

class RAGService:
    def __init__(self, llm_client, vector_db):
        self.llm = llm_client
        self.vdb = vector_db
    def rewrite_query(self, user_input: str):
        """ç¬¬ä¸€æ­¥ï¼šæ„å›¾è¯†åˆ«ä¸å…³é”®è¯é‡å†™"""
        prompt = prompts.QUERY_REWRITE_TEMPLATE.format(user_input=user_input)
        response = self.llm.chat(
            prompt,
            temperature=0.01,
            top_p=0.1,
            max_tokens=8192
        )
        return robust_json_parser(response)

    def retrieve_docs(self, query, law_name, user_input):
        if self.vdb is None:
            return []

        """ç¬¬äºŒæ­¥ï¼šå‘é‡åº“æ£€ç´¢"""
        if not law_name.startswith("ä¸­åäººæ°‘å…±å’Œå›½"):
            law_name = "ä¸­åäººæ°‘å…±å’Œå›½" + law_name

        return legal_search(self.vdb, query, law_name, user_input)

    def generate_answer(self, user_input, docs):
        if not docs:
            return "æœªæ£€ç´¢åˆ°ç›¸å…³æ³•å¾‹æ¡æ–‡ã€‚"

        # è·å–æœ€ç›¸å…³æ–‡æ¡£çš„åˆ†æ•°
        best_score = docs[0].metadata.get('score', 1.0)

        # é˜ˆå€¼æ§åˆ¶ï¼šå¦‚æœåˆ†å€¼ï¼ˆè·ç¦»ï¼‰å¤§äº 0.6ï¼Œè¯´æ˜è¯­ä¹‰ä¸Šå·²ç»ä¸ç›¸å…³äº†
        if best_score > 0.6:
            return "æŠ±æ­‰ï¼Œæ£€ç´¢åˆ°çš„æ³•å¾‹æ¡æ–‡ç›¸å…³æ€§è¾ƒä½ï¼Œå»ºè®®å’¨è¯¢äººå·¥å¾‹å¸ˆã€‚"

        """ç¬¬ä¸‰æ­¥ï¼šåŸºäºä¸Šä¸‹æ–‡ç”Ÿæˆç­”æ¡ˆ"""
        content = "\n".join([d.page_content for d in docs])
        prompt = prompts.RAG_GENERATE_TEMPLATE.format(content=content, user_input=user_input)
        llm_raw_output = self.llm.chat(
            prompt,
            temperature=0.01,
            top_p=0.1,
            max_tokens=8192,
        )
        # 1. é¢„è§£æ LLM è¾“å‡ºçš„ JSON
        analysis = robust_json_parser(llm_raw_output)
        # 2. ä»æ£€ç´¢åˆ°çš„ docs ä¸­æå–çœŸå®æ³•æ¡ä¿¡æ¯ï¼ˆä¿è¯ç»å¯¹å‡†ç¡®ï¼‰
        law_title = docs[0].metadata.get("article_name", "ç›¸å…³æ³•å¾‹æ¡æ¬¾")
        law_content = docs[0].page_content
        # 3. ä½¿ç”¨Markdownç¾åŒ–æ’ç‰ˆ
        tips_str = "\n".join([f"- {tip}" for tip in analysis.get("risk_tips", [])])
        final_report = REPLY_REPORT_TEMPLATE.format(
            law_title=law_title,
            law_content=law_content,
            intent_analysis=analysis.get("intent_analysis", "æœªçŸ¥åœºæ™¯"),
            conclusion=analysis.get("conclusion", "è¯·å’¨è¯¢äººå·¥ç¡®è®¤"),
            detailed_logic=analysis.get("detailed_logic", "åˆ†æè¿‡ç¨‹ç¼ºå¤±"),
            risk_tips=tips_str
        )

        return final_report

    def call_rag_flow(self, user_input):
        # 1. é‡å†™
        try:
            intent = self.rewrite_query(user_input)
            search_words = intent.get('search_words', user_input)
            law_name = intent.get('law_name', '')
        except Exception as e:
            search_words, law_name = user_input, ""

        # 2. æ£€ç´¢
        docs = self.retrieve_docs(search_words, law_name, user_input)

        # 3. ç”Ÿæˆ
        return self.generate_answer(user_input, docs)